{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be73fb03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T00:50:50.449479Z",
     "iopub.status.busy": "2025-07-30T00:50:50.449217Z",
     "iopub.status.idle": "2025-07-30T00:52:21.286531Z",
     "shell.execute_reply": "2025-07-30T00:52:21.285856Z"
    },
    "papermill": {
     "duration": 90.842461,
     "end_time": "2025-07-30T00:52:21.288022",
     "exception": false,
     "start_time": "2025-07-30T00:50:50.445561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -qq medmnist\n",
    "!pip install -qq av\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5bd27e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T00:52:21.333251Z",
     "iopub.status.busy": "2025-07-30T00:52:21.332687Z",
     "iopub.status.idle": "2025-07-30T00:52:21.398210Z",
     "shell.execute_reply": "2025-07-30T00:52:21.397643Z"
    },
    "papermill": {
     "duration": 0.087191,
     "end_time": "2025-07-30T00:52:21.399416",
     "exception": false,
     "start_time": "2025-07-30T00:52:21.312225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATA_DIR = '/kaggle/input/hanwash/HandWashDataset/HandWashDataset'\n",
    "CLASSES = ['Step_1', 'Step_2', 'Step_3', 'Step_4', 'Step_5', 'Step_6']\n",
    "LABELS_TO_ID = {label: i for i, label in enumerate(CLASSES)}\n",
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.2\n",
    "DATASET_SEED = 81\n",
    "FRAME_SIZE = (360, 240)\n",
    "SCALE = 255.0\n",
    "CLIP_LENGTH = 100\n",
    "INPUT_SHAPE = (1, 210, 270)  # PyTorch: (C, H, W)\n",
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "EPOCHS = 200\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b227b16b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T00:52:21.441248Z",
     "iopub.status.busy": "2025-07-30T00:52:21.440996Z",
     "iopub.status.idle": "2025-07-30T00:52:21.451859Z",
     "shell.execute_reply": "2025-07-30T00:52:21.451386Z"
    },
    "papermill": {
     "duration": 0.033613,
     "end_time": "2025-07-30T00:52:21.452954",
     "exception": false,
     "start_time": "2025-07-30T00:52:21.419341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(data_dir, classes, test_size=TEST_SIZE, val_size=VAL_SIZE, random_state=DATASET_SEED):\n",
    "    video_lengths = []\n",
    "    for class_name in classes:\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        videos = os.listdir(class_dir)\n",
    "        for video_file in videos:\n",
    "            video_path = os.path.join(class_dir, video_file)\n",
    "            video_reader = cv2.VideoCapture(video_path)\n",
    "            frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            video_lengths.append((class_name, video_path, frames_count))\n",
    "            video_reader.release()\n",
    "    train_videos, test_val_videos = train_test_split(video_lengths, test_size=test_size+val_size, random_state=random_state)\n",
    "    val_videos, test_videos = train_test_split(test_val_videos, test_size=test_size/(test_size+val_size), random_state=random_state)\n",
    "    return train_videos, val_videos, test_videos\n",
    "\n",
    "def read_video_pyav(container, indices, new_size=FRAME_SIZE, scale=SCALE):\n",
    "    frames = []\n",
    "    container.seek(0)\n",
    "    start_index = indices[0]\n",
    "    end_index = indices[-1]\n",
    "    for i, frame in enumerate(container.decode(video=0)):\n",
    "        if i > end_index:\n",
    "            break\n",
    "        if i >= start_index and i in indices:\n",
    "            new_frame = frame.to_ndarray(format=\"rgb24\")\n",
    "            new_frame = cv2.cvtColor(new_frame, cv2.COLOR_RGB2GRAY)\n",
    "            new_frame = new_frame / scale\n",
    "            new_frame = cv2.resize(new_frame, new_size)\n",
    "            frames.append(new_frame)\n",
    "    return np.stack(frames, axis=0)  # Shape: (num_frames, H, W)\n",
    "\n",
    "def sample_frame_indices(frame_sample_rate, seg_len, clip_len=CLIP_LENGTH):\n",
    "    converted_len = int(clip_len * frame_sample_rate)\n",
    "    end_idx = seg_len\n",
    "    start_idx = end_idx - converted_len\n",
    "    indices = np.linspace(start_idx, end_idx, num=clip_len)\n",
    "    indices = np.clip(indices, start_idx, end_idx - 1).astype(np.int64)\n",
    "    return indices\n",
    "\n",
    "def download_and_prepare_dataset(video_directories: list):\n",
    "    np_videos = []\n",
    "    valid_indices = []\n",
    "    for i, address in enumerate(video_directories):\n",
    "        try:\n",
    "            vid_container = av.open(address)\n",
    "            vid_indices = sample_frame_indices(frame_sample_rate=1, seg_len=vid_container.streams.video[0].frames)\n",
    "            video_frames = read_video_pyav(container=vid_container, indices=vid_indices)\n",
    "            if video_frames.shape[0] != CLIP_LENGTH:\n",
    "                print(f\"Warning: Video {i} at {address} has {video_frames.shape[0]} frames, expected {CLIP_LENGTH}. Skipping.\")\n",
    "                continue\n",
    "            np_videos.append(video_frames)\n",
    "            valid_indices.append(i)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing video {i} at {address}: {str(e)}\")\n",
    "    return np_videos, valid_indices\n",
    "\n",
    "def preprocess_dataset(list_of_videos, list_of_labels, valid_indices, new_size=FRAME_SIZE, clip_len=CLIP_LENGTH):\n",
    "    total_frames = len(list_of_videos) * clip_len\n",
    "    resized_list = np.zeros((total_frames, new_size[1], new_size[0]), dtype=np.float32)\n",
    "    resized_labels = np.zeros(total_frames, dtype=np.int64)\n",
    "    valid_frame_count = 0\n",
    "    for i, video in enumerate(list_of_videos):\n",
    "        if video.shape[0] != clip_len:\n",
    "            print(f\"Warning: Video {i} has {video.shape[0]} frames, expected {clip_len}. Skipping.\")\n",
    "            continue\n",
    "        for j in range(clip_len):\n",
    "            resized_list[valid_frame_count] = video[j]\n",
    "            # Ép kiểu nhãn thành int64\n",
    "            resized_labels[valid_frame_count] = int(list_of_labels[valid_indices[i]])\n",
    "            valid_frame_count += 1\n",
    "    resized_list = resized_list[:valid_frame_count]\n",
    "    resized_labels = resized_labels[:valid_frame_count]\n",
    "    return resized_list, resized_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a465b9c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T00:52:21.492810Z",
     "iopub.status.busy": "2025-07-30T00:52:21.492593Z",
     "iopub.status.idle": "2025-07-30T00:52:21.497985Z",
     "shell.execute_reply": "2025-07-30T00:52:21.497318Z"
    },
    "papermill": {
     "duration": 0.02646,
     "end_time": "2025-07-30T00:52:21.499071",
     "exception": false,
     "start_time": "2025-07-30T00:52:21.472611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HandWashDataset(Dataset):\n",
    "    def __init__(self, videos, labels, transform=None):\n",
    "        self.videos = videos\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.videos)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            frame = self.videos[idx]\n",
    "            label = self.labels[idx]\n",
    "            if frame.ndim != 2:\n",
    "                raise ValueError(f\"Frame at index {idx} has shape {frame.shape}, expected 2D (H, W)\")\n",
    "            frame = frame[..., np.newaxis]\n",
    "            frame = torch.from_numpy(frame).permute(2, 0, 1).float()\n",
    "            if self.transform:\n",
    "                frame = self.transform(frame)\n",
    "            return frame, torch.tensor(label, dtype=torch.long)\n",
    "        except Exception as e:\n",
    "            print(f\"Transform error at index {idx}: {str(e)}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "885d95c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T00:52:21.540878Z",
     "iopub.status.busy": "2025-07-30T00:52:21.540666Z",
     "iopub.status.idle": "2025-07-30T00:52:21.544646Z",
     "shell.execute_reply": "2025-07-30T00:52:21.543973Z"
    },
    "papermill": {
     "duration": 0.02588,
     "end_time": "2025-07-30T00:52:21.545780",
     "exception": false,
     "start_time": "2025-07-30T00:52:21.519900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop((210, 270)),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2),\n",
    "])\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((210, 270)),  # Thêm Resize để khớp với INPUT_SHAPE\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "422274bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T00:52:21.585794Z",
     "iopub.status.busy": "2025-07-30T00:52:21.585577Z",
     "iopub.status.idle": "2025-07-30T00:52:29.644169Z",
     "shell.execute_reply": "2025-07-30T00:52:29.643377Z"
    },
    "papermill": {
     "duration": 8.080202,
     "end_time": "2025-07-30T00:52:29.645709",
     "exception": false,
     "start_time": "2025-07-30T00:52:21.565507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Chuẩn bị dữ liệu\n",
    "train_info, val_info, test_info = prepare_dataset(DATA_DIR, CLASSES)\n",
    "train_addr = [info[1] for info in train_info]\n",
    "train_names = [LABELS_TO_ID[info[0]] for info in train_info]\n",
    "val_addr = [info[1] for info in val_info]\n",
    "val_names = [LABELS_TO_ID[info[0]] for info in val_info]\n",
    "test_addr = [info[1] for info in test_info]\n",
    "test_names = [LABELS_TO_ID[info[0]] for info in test_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c379cca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T00:52:29.732644Z",
     "iopub.status.busy": "2025-07-30T00:52:29.732069Z",
     "iopub.status.idle": "2025-07-30T01:01:08.683741Z",
     "shell.execute_reply": "2025-07-30T01:01:08.682906Z"
    },
    "papermill": {
     "duration": 518.994128,
     "end_time": "2025-07-30T01:01:08.705607",
     "exception": false,
     "start_time": "2025-07-30T00:52:29.711479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with train\n",
      "done with val\n",
      "done with test\n"
     ]
    }
   ],
   "source": [
    "train_videos, train_valid_indices = download_and_prepare_dataset(train_addr)\n",
    "train_videos, train_labels = preprocess_dataset(train_videos, train_names, train_valid_indices)\n",
    "print(\"done with train\")\n",
    "val_videos, val_valid_indices = download_and_prepare_dataset(val_addr)\n",
    "val_videos, val_labels = preprocess_dataset(val_videos, val_names, val_valid_indices)\n",
    "print(\"done with val\")\n",
    "test_videos, test_valid_indices = download_and_prepare_dataset(test_addr)\n",
    "test_videos, test_labels = preprocess_dataset(test_videos, test_names, test_valid_indices)\n",
    "print(\"done with test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a59cf9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:01:08.747016Z",
     "iopub.status.busy": "2025-07-30T01:01:08.746405Z",
     "iopub.status.idle": "2025-07-30T01:01:08.750353Z",
     "shell.execute_reply": "2025-07-30T01:01:08.749724Z"
    },
    "papermill": {
     "duration": 0.025722,
     "end_time": "2025-07-30T01:01:08.751416",
     "exception": false,
     "start_time": "2025-07-30T01:01:08.725694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = HandWashDataset(train_videos, train_labels, transform=train_transform)\n",
    "val_dataset = HandWashDataset(val_videos, val_labels, transform=val_test_transform)\n",
    "test_dataset = HandWashDataset(test_videos, test_labels, transform=val_test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d2d8c1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:01:08.793154Z",
     "iopub.status.busy": "2025-07-30T01:01:08.792707Z",
     "iopub.status.idle": "2025-07-30T01:01:08.796968Z",
     "shell.execute_reply": "2025-07-30T01:01:08.796317Z"
    },
    "papermill": {
     "duration": 0.025972,
     "end_time": "2025-07-30T01:01:08.797934",
     "exception": false,
     "start_time": "2025-07-30T01:01:08.771962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "validloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "testloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ce13ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:01:08.839343Z",
     "iopub.status.busy": "2025-07-30T01:01:08.839156Z",
     "iopub.status.idle": "2025-07-30T01:01:08.848171Z",
     "shell.execute_reply": "2025-07-30T01:01:08.847601Z"
    },
    "papermill": {
     "duration": 0.031344,
     "end_time": "2025-07-30T01:01:08.849285",
     "exception": false,
     "start_time": "2025-07-30T01:01:08.817941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class HandWashResNet(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES):\n",
    "        super(HandWashResNet, self).__init__()\n",
    "        self.model = models.resnet18(weights='DEFAULT')  # Chuyển sang ResNet18\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Hàm huấn luyện và đánh giá\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    train_loss = running_loss / len(dataloader)\n",
    "    train_acc = 100 * correct / total\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            _, predicted_top5 = outputs.topk(5, dim=1)\n",
    "            correct_top5 += sum([labels[i] in predicted_top5[i] for i in range(labels.size(0))])\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    accuracy = 100 * correct / total\n",
    "    top5_accuracy = 100 * correct_top5 / total\n",
    "    return avg_loss, accuracy, top5_accuracy, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc29a756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:01:08.890308Z",
     "iopub.status.busy": "2025-07-30T01:01:08.890124Z",
     "iopub.status.idle": "2025-07-30T02:56:02.109470Z",
     "shell.execute_reply": "2025-07-30T02:56:02.108193Z"
    },
    "papermill": {
     "duration": 6893.241482,
     "end_time": "2025-07-30T02:56:02.110912",
     "exception": false,
     "start_time": "2025-07-30T01:01:08.869430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 187MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 - Train Loss: 0.2414, Train Acc: 92.54%\n",
      "Val Loss: 0.2816, Val Acc: 90.28%, Val Top-5 Acc: 100.00%\n",
      "Saved best full model at epoch 1 with val_loss: 0.2816, val_acc: 90.28%\n",
      "Epoch 2/200 - Train Loss: 0.0177, Train Acc: 99.61%\n",
      "Val Loss: 0.2679, Val Acc: 91.08%, Val Top-5 Acc: 100.00%\n",
      "Saved best full model at epoch 2 with val_loss: 0.2679, val_acc: 91.08%\n",
      "Epoch 3/200 - Train Loss: 0.0154, Train Acc: 99.63%\n",
      "Val Loss: 0.1430, Val Acc: 95.12%, Val Top-5 Acc: 100.00%\n",
      "Saved best full model at epoch 3 with val_loss: 0.1430, val_acc: 95.12%\n",
      "Epoch 4/200 - Train Loss: 0.0065, Train Acc: 99.84%\n",
      "Val Loss: 0.1728, Val Acc: 93.90%, Val Top-5 Acc: 100.00%\n",
      "Epoch 5/200 - Train Loss: 0.0099, Train Acc: 99.74%\n",
      "Val Loss: 0.0900, Val Acc: 97.22%, Val Top-5 Acc: 100.00%\n",
      "Saved best full model at epoch 5 with val_loss: 0.0900, val_acc: 97.22%\n",
      "Epoch 6/200 - Train Loss: 0.0053, Train Acc: 99.89%\n",
      "Val Loss: 0.1225, Val Acc: 96.28%, Val Top-5 Acc: 100.00%\n",
      "Epoch 7/200 - Train Loss: 0.0025, Train Acc: 99.94%\n",
      "Val Loss: 0.1603, Val Acc: 93.92%, Val Top-5 Acc: 99.70%\n",
      "Epoch 8/200 - Train Loss: 0.0138, Train Acc: 99.61%\n",
      "Val Loss: 0.2545, Val Acc: 92.34%, Val Top-5 Acc: 100.00%\n",
      "Epoch 9/200 - Train Loss: 0.0071, Train Acc: 99.76%\n",
      "Val Loss: 0.3571, Val Acc: 87.20%, Val Top-5 Acc: 99.98%\n",
      "Epoch 10/200 - Train Loss: 0.0044, Train Acc: 99.87%\n",
      "Val Loss: 0.1201, Val Acc: 95.90%, Val Top-5 Acc: 100.00%\n",
      "Epoch 11/200 - Train Loss: 0.0008, Train Acc: 99.99%\n",
      "Val Loss: 0.0853, Val Acc: 97.42%, Val Top-5 Acc: 100.00%\n",
      "Saved best full model at epoch 11 with val_loss: 0.0853, val_acc: 97.42%\n",
      "Epoch 12/200 - Train Loss: 0.0006, Train Acc: 99.99%\n",
      "Val Loss: 0.0751, Val Acc: 97.38%, Val Top-5 Acc: 100.00%\n",
      "Epoch 13/200 - Train Loss: 0.0002, Train Acc: 100.00%\n",
      "Val Loss: 0.0821, Val Acc: 97.06%, Val Top-5 Acc: 100.00%\n",
      "Epoch 14/200 - Train Loss: 0.0002, Train Acc: 100.00%\n",
      "Val Loss: 0.0954, Val Acc: 96.52%, Val Top-5 Acc: 100.00%\n",
      "Epoch 15/200 - Train Loss: 0.0023, Train Acc: 99.95%\n",
      "Val Loss: 0.1855, Val Acc: 93.70%, Val Top-5 Acc: 100.00%\n",
      "Epoch 16/200 - Train Loss: 0.0101, Train Acc: 99.73%\n",
      "Val Loss: 0.2068, Val Acc: 92.86%, Val Top-5 Acc: 100.00%\n",
      "Epoch 17/200 - Train Loss: 0.0093, Train Acc: 99.71%\n",
      "Val Loss: 0.3194, Val Acc: 89.70%, Val Top-5 Acc: 100.00%\n",
      "Epoch 18/200 - Train Loss: 0.0096, Train Acc: 99.73%\n",
      "Val Loss: 0.1050, Val Acc: 96.56%, Val Top-5 Acc: 100.00%\n",
      "Epoch 19/200 - Train Loss: 0.0010, Train Acc: 99.99%\n",
      "Val Loss: 0.0911, Val Acc: 97.26%, Val Top-5 Acc: 100.00%\n",
      "Epoch 20/200 - Train Loss: 0.0021, Train Acc: 99.95%\n",
      "Val Loss: 0.1357, Val Acc: 96.02%, Val Top-5 Acc: 100.00%\n",
      "Epoch 21/200 - Train Loss: 0.0019, Train Acc: 99.95%\n",
      "Val Loss: 0.1210, Val Acc: 95.84%, Val Top-5 Acc: 100.00%\n",
      "Epoch 22/200 - Train Loss: 0.0008, Train Acc: 99.98%\n",
      "Val Loss: 0.1146, Val Acc: 96.16%, Val Top-5 Acc: 100.00%\n",
      "Epoch 23/200 - Train Loss: 0.0003, Train Acc: 99.99%\n",
      "Val Loss: 0.1196, Val Acc: 96.02%, Val Top-5 Acc: 100.00%\n",
      "Epoch 24/200 - Train Loss: 0.0005, Train Acc: 99.99%\n",
      "Val Loss: 0.1774, Val Acc: 94.54%, Val Top-5 Acc: 100.00%\n",
      "Epoch 25/200 - Train Loss: 0.0024, Train Acc: 99.96%\n",
      "Val Loss: 0.1627, Val Acc: 94.24%, Val Top-5 Acc: 100.00%\n",
      "Epoch 26/200 - Train Loss: 0.0035, Train Acc: 99.91%\n",
      "Val Loss: 0.2369, Val Acc: 93.90%, Val Top-5 Acc: 100.00%\n",
      "Epoch 27/200 - Train Loss: 0.0037, Train Acc: 99.91%\n",
      "Val Loss: 0.1995, Val Acc: 92.84%, Val Top-5 Acc: 100.00%\n",
      "Epoch 28/200 - Train Loss: 0.0119, Train Acc: 99.67%\n",
      "Val Loss: 0.3071, Val Acc: 90.64%, Val Top-5 Acc: 100.00%\n",
      "Epoch 29/200 - Train Loss: 0.0022, Train Acc: 99.94%\n",
      "Val Loss: 0.1401, Val Acc: 95.56%, Val Top-5 Acc: 100.00%\n",
      "Epoch 30/200 - Train Loss: 0.0008, Train Acc: 99.99%\n",
      "Val Loss: 0.0864, Val Acc: 97.80%, Val Top-5 Acc: 100.00%\n",
      "Epoch 31/200 - Train Loss: 0.0044, Train Acc: 99.86%\n",
      "Val Loss: 0.1167, Val Acc: 96.42%, Val Top-5 Acc: 100.00%\n",
      "Epoch 32/200 - Train Loss: 0.0014, Train Acc: 99.97%\n",
      "Val Loss: 0.1028, Val Acc: 97.42%, Val Top-5 Acc: 100.00%\n",
      "Epoch 33/200 - Train Loss: 0.0002, Train Acc: 100.00%\n",
      "Val Loss: 0.1380, Val Acc: 95.80%, Val Top-5 Acc: 100.00%\n",
      "Epoch 34/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.0769, Val Acc: 98.34%, Val Top-5 Acc: 100.00%\n",
      "Saved best full model at epoch 34 with val_loss: 0.0769, val_acc: 98.34%\n",
      "Epoch 35/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.0572, Val Acc: 98.38%, Val Top-5 Acc: 100.00%\n",
      "Saved best full model at epoch 35 with val_loss: 0.0572, val_acc: 98.38%\n",
      "Epoch 36/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.0767, Val Acc: 97.70%, Val Top-5 Acc: 100.00%\n",
      "Epoch 37/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.0803, Val Acc: 97.70%, Val Top-5 Acc: 100.00%\n",
      "Epoch 38/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.0767, Val Acc: 97.78%, Val Top-5 Acc: 100.00%\n",
      "Epoch 39/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.0865, Val Acc: 97.38%, Val Top-5 Acc: 100.00%\n",
      "Epoch 40/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.0736, Val Acc: 97.96%, Val Top-5 Acc: 100.00%\n",
      "Epoch 41/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.0723, Val Acc: 97.94%, Val Top-5 Acc: 100.00%\n",
      "Epoch 42/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.0646, Val Acc: 98.04%, Val Top-5 Acc: 100.00%\n",
      "Epoch 43/200 - Train Loss: 0.0193, Train Acc: 99.41%\n",
      "Val Loss: 0.2344, Val Acc: 92.32%, Val Top-5 Acc: 100.00%\n",
      "Epoch 44/200 - Train Loss: 0.0041, Train Acc: 99.87%\n",
      "Val Loss: 0.2272, Val Acc: 92.46%, Val Top-5 Acc: 100.00%\n",
      "Epoch 45/200 - Train Loss: 0.0050, Train Acc: 99.84%\n",
      "Val Loss: 0.3519, Val Acc: 86.90%, Val Top-5 Acc: 100.00%\n",
      "Epoch 46/200 - Train Loss: 0.0006, Train Acc: 99.99%\n",
      "Val Loss: 0.1046, Val Acc: 96.52%, Val Top-5 Acc: 100.00%\n",
      "Epoch 47/200 - Train Loss: 0.0002, Train Acc: 100.00%\n",
      "Val Loss: 0.1257, Val Acc: 95.92%, Val Top-5 Acc: 100.00%\n",
      "Epoch 48/200 - Train Loss: 0.0002, Train Acc: 100.00%\n",
      "Val Loss: 0.0817, Val Acc: 97.20%, Val Top-5 Acc: 100.00%\n",
      "Epoch 49/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.0805, Val Acc: 97.50%, Val Top-5 Acc: 100.00%\n",
      "Epoch 50/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.0763, Val Acc: 97.84%, Val Top-5 Acc: 100.00%\n",
      "Epoch 51/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.0943, Val Acc: 97.26%, Val Top-5 Acc: 100.00%\n",
      "Epoch 52/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.0905, Val Acc: 97.28%, Val Top-5 Acc: 100.00%\n",
      "Epoch 53/200 - Train Loss: 0.0039, Train Acc: 99.89%\n",
      "Val Loss: 2.0819, Val Acc: 63.66%, Val Top-5 Acc: 99.96%\n",
      "Epoch 54/200 - Train Loss: 0.0091, Train Acc: 99.73%\n",
      "Val Loss: 0.2367, Val Acc: 92.72%, Val Top-5 Acc: 100.00%\n",
      "Epoch 55/200 - Train Loss: 0.0005, Train Acc: 100.00%\n",
      "Val Loss: 0.2244, Val Acc: 92.84%, Val Top-5 Acc: 100.00%\n",
      "Epoch 56/200 - Train Loss: 0.0002, Train Acc: 100.00%\n",
      "Val Loss: 0.1379, Val Acc: 95.46%, Val Top-5 Acc: 100.00%\n",
      "Epoch 57/200 - Train Loss: 0.0008, Train Acc: 99.98%\n",
      "Val Loss: 0.3034, Val Acc: 91.24%, Val Top-5 Acc: 100.00%\n",
      "Epoch 58/200 - Train Loss: 0.0020, Train Acc: 99.94%\n",
      "Val Loss: 0.2037, Val Acc: 94.16%, Val Top-5 Acc: 99.96%\n",
      "Epoch 59/200 - Train Loss: 0.0013, Train Acc: 99.97%\n",
      "Val Loss: 0.2658, Val Acc: 92.36%, Val Top-5 Acc: 99.98%\n",
      "Epoch 60/200 - Train Loss: 0.0002, Train Acc: 100.00%\n",
      "Val Loss: 0.2314, Val Acc: 92.60%, Val Top-5 Acc: 99.96%\n",
      "Epoch 61/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.1483, Val Acc: 94.64%, Val Top-5 Acc: 100.00%\n",
      "Epoch 62/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.1736, Val Acc: 93.84%, Val Top-5 Acc: 100.00%\n",
      "Epoch 63/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.1410, Val Acc: 94.98%, Val Top-5 Acc: 100.00%\n",
      "Epoch 64/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.1366, Val Acc: 94.68%, Val Top-5 Acc: 100.00%\n",
      "Epoch 65/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.0915, Val Acc: 97.16%, Val Top-5 Acc: 100.00%\n",
      "Epoch 66/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.0969, Val Acc: 97.14%, Val Top-5 Acc: 100.00%\n",
      "Epoch 67/200 - Train Loss: 0.0002, Train Acc: 100.00%\n",
      "Val Loss: 0.1378, Val Acc: 95.82%, Val Top-5 Acc: 99.96%\n",
      "Epoch 68/200 - Train Loss: 0.0123, Train Acc: 99.65%\n",
      "Val Loss: 0.1228, Val Acc: 96.24%, Val Top-5 Acc: 100.00%\n",
      "Epoch 69/200 - Train Loss: 0.0031, Train Acc: 99.92%\n",
      "Val Loss: 0.1650, Val Acc: 95.04%, Val Top-5 Acc: 100.00%\n",
      "Epoch 70/200 - Train Loss: 0.0012, Train Acc: 99.98%\n",
      "Val Loss: 0.1540, Val Acc: 95.14%, Val Top-5 Acc: 100.00%\n",
      "Epoch 71/200 - Train Loss: 0.0011, Train Acc: 99.98%\n",
      "Val Loss: 0.1619, Val Acc: 95.18%, Val Top-5 Acc: 100.00%\n",
      "Epoch 72/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.1605, Val Acc: 94.74%, Val Top-5 Acc: 100.00%\n",
      "Epoch 73/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.1857, Val Acc: 93.84%, Val Top-5 Acc: 100.00%\n",
      "Epoch 74/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.1334, Val Acc: 95.32%, Val Top-5 Acc: 100.00%\n",
      "Epoch 75/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.1195, Val Acc: 95.88%, Val Top-5 Acc: 100.00%\n",
      "Epoch 76/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.1151, Val Acc: 95.98%, Val Top-5 Acc: 100.00%\n",
      "Epoch 77/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.1460, Val Acc: 94.64%, Val Top-5 Acc: 100.00%\n",
      "Epoch 78/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.1320, Val Acc: 95.20%, Val Top-5 Acc: 100.00%\n",
      "Epoch 79/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.1194, Val Acc: 95.84%, Val Top-5 Acc: 100.00%\n",
      "Epoch 80/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.1153, Val Acc: 96.54%, Val Top-5 Acc: 100.00%\n",
      "Epoch 81/200 - Train Loss: 0.0008, Train Acc: 99.98%\n",
      "Val Loss: 0.2937, Val Acc: 91.14%, Val Top-5 Acc: 99.94%\n",
      "Epoch 82/200 - Train Loss: 0.0150, Train Acc: 99.59%\n",
      "Val Loss: 0.2458, Val Acc: 92.70%, Val Top-5 Acc: 99.28%\n",
      "Epoch 83/200 - Train Loss: 0.0036, Train Acc: 99.90%\n",
      "Val Loss: 0.1287, Val Acc: 96.12%, Val Top-5 Acc: 100.00%\n",
      "Epoch 84/200 - Train Loss: 0.0007, Train Acc: 99.99%\n",
      "Val Loss: 0.1991, Val Acc: 93.94%, Val Top-5 Acc: 100.00%\n",
      "Epoch 85/200 - Train Loss: 0.0002, Train Acc: 100.00%\n",
      "Val Loss: 0.1258, Val Acc: 95.90%, Val Top-5 Acc: 100.00%\n",
      "Epoch 86/200 - Train Loss: 0.0002, Train Acc: 100.00%\n",
      "Val Loss: 0.0875, Val Acc: 97.44%, Val Top-5 Acc: 100.00%\n",
      "Epoch 87/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.1256, Val Acc: 95.94%, Val Top-5 Acc: 100.00%\n",
      "Epoch 88/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.0847, Val Acc: 97.02%, Val Top-5 Acc: 100.00%\n",
      "Epoch 89/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.0617, Val Acc: 98.28%, Val Top-5 Acc: 100.00%\n",
      "Epoch 90/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.0553, Val Acc: 98.38%, Val Top-5 Acc: 100.00%\n",
      "Epoch 91/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.0584, Val Acc: 98.30%, Val Top-5 Acc: 100.00%\n",
      "Epoch 92/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.0577, Val Acc: 98.36%, Val Top-5 Acc: 100.00%\n",
      "Epoch 93/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.1134, Val Acc: 96.74%, Val Top-5 Acc: 100.00%\n",
      "Epoch 94/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.0821, Val Acc: 97.84%, Val Top-5 Acc: 100.00%\n",
      "Epoch 95/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.0710, Val Acc: 97.82%, Val Top-5 Acc: 100.00%\n",
      "Epoch 96/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.0679, Val Acc: 98.00%, Val Top-5 Acc: 100.00%\n",
      "Epoch 97/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.0753, Val Acc: 97.62%, Val Top-5 Acc: 100.00%\n",
      "Epoch 98/200 - Train Loss: 0.0186, Train Acc: 99.49%\n",
      "Val Loss: 0.1805, Val Acc: 94.92%, Val Top-5 Acc: 100.00%\n",
      "Epoch 99/200 - Train Loss: 0.0011, Train Acc: 99.97%\n",
      "Val Loss: 0.1859, Val Acc: 94.64%, Val Top-5 Acc: 100.00%\n",
      "Epoch 100/200 - Train Loss: 0.0002, Train Acc: 100.00%\n",
      "Val Loss: 0.2022, Val Acc: 94.64%, Val Top-5 Acc: 100.00%\n",
      "Epoch 101/200 - Train Loss: 0.0002, Train Acc: 100.00%\n",
      "Val Loss: 0.2363, Val Acc: 94.48%, Val Top-5 Acc: 100.00%\n",
      "Epoch 102/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.1883, Val Acc: 95.74%, Val Top-5 Acc: 100.00%\n",
      "Epoch 103/200 - Train Loss: 0.0009, Train Acc: 99.97%\n",
      "Val Loss: 0.1656, Val Acc: 94.32%, Val Top-5 Acc: 100.00%\n",
      "Epoch 104/200 - Train Loss: 0.0015, Train Acc: 99.95%\n",
      "Val Loss: 0.5721, Val Acc: 84.06%, Val Top-5 Acc: 100.00%\n",
      "Epoch 105/200 - Train Loss: 0.0060, Train Acc: 99.88%\n",
      "Val Loss: 0.1549, Val Acc: 95.16%, Val Top-5 Acc: 100.00%\n",
      "Epoch 106/200 - Train Loss: 0.0022, Train Acc: 99.95%\n",
      "Val Loss: 0.1989, Val Acc: 93.98%, Val Top-5 Acc: 100.00%\n",
      "Epoch 107/200 - Train Loss: 0.0002, Train Acc: 100.00%\n",
      "Val Loss: 0.1422, Val Acc: 95.66%, Val Top-5 Acc: 100.00%\n",
      "Epoch 108/200 - Train Loss: 0.0009, Train Acc: 99.97%\n",
      "Val Loss: 0.1346, Val Acc: 95.96%, Val Top-5 Acc: 100.00%\n",
      "Epoch 109/200 - Train Loss: 0.0043, Train Acc: 99.89%\n",
      "Val Loss: 0.1418, Val Acc: 95.18%, Val Top-5 Acc: 99.92%\n",
      "Epoch 110/200 - Train Loss: 0.0002, Train Acc: 100.00%\n",
      "Val Loss: 0.1333, Val Acc: 95.54%, Val Top-5 Acc: 99.96%\n",
      "Epoch 111/200 - Train Loss: 0.0025, Train Acc: 99.95%\n",
      "Val Loss: 0.1682, Val Acc: 94.48%, Val Top-5 Acc: 100.00%\n",
      "Epoch 112/200 - Train Loss: 0.0014, Train Acc: 99.96%\n",
      "Val Loss: 0.1189, Val Acc: 95.94%, Val Top-5 Acc: 99.96%\n",
      "Epoch 113/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.0851, Val Acc: 97.18%, Val Top-5 Acc: 99.96%\n",
      "Epoch 114/200 - Train Loss: 0.0003, Train Acc: 99.99%\n",
      "Val Loss: 0.1462, Val Acc: 95.34%, Val Top-5 Acc: 100.00%\n",
      "Epoch 115/200 - Train Loss: 0.0007, Train Acc: 99.98%\n",
      "Val Loss: 0.1385, Val Acc: 94.28%, Val Top-5 Acc: 100.00%\n",
      "Epoch 116/200 - Train Loss: 0.0106, Train Acc: 99.73%\n",
      "Val Loss: 0.2976, Val Acc: 91.30%, Val Top-5 Acc: 100.00%\n",
      "Epoch 117/200 - Train Loss: 0.0012, Train Acc: 99.97%\n",
      "Val Loss: 0.1764, Val Acc: 94.36%, Val Top-5 Acc: 100.00%\n",
      "Epoch 118/200 - Train Loss: 0.0023, Train Acc: 99.95%\n",
      "Val Loss: 0.0818, Val Acc: 97.78%, Val Top-5 Acc: 100.00%\n",
      "Epoch 119/200 - Train Loss: 0.0010, Train Acc: 99.97%\n",
      "Val Loss: 0.1126, Val Acc: 96.14%, Val Top-5 Acc: 100.00%\n",
      "Epoch 120/200 - Train Loss: 0.0008, Train Acc: 99.98%\n",
      "Val Loss: 0.1923, Val Acc: 95.26%, Val Top-5 Acc: 100.00%\n",
      "Epoch 121/200 - Train Loss: 0.0004, Train Acc: 99.99%\n",
      "Val Loss: 0.1282, Val Acc: 95.42%, Val Top-5 Acc: 100.00%\n",
      "Epoch 122/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.1133, Val Acc: 95.96%, Val Top-5 Acc: 100.00%\n",
      "Epoch 123/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.1142, Val Acc: 95.60%, Val Top-5 Acc: 100.00%\n",
      "Epoch 124/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.1097, Val Acc: 96.08%, Val Top-5 Acc: 100.00%\n",
      "Epoch 125/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.0937, Val Acc: 96.60%, Val Top-5 Acc: 100.00%\n",
      "Epoch 126/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.1181, Val Acc: 95.80%, Val Top-5 Acc: 100.00%\n",
      "Epoch 127/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.0893, Val Acc: 97.14%, Val Top-5 Acc: 100.00%\n",
      "Epoch 128/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.0812, Val Acc: 97.50%, Val Top-5 Acc: 100.00%\n",
      "Epoch 129/200 - Train Loss: 0.0059, Train Acc: 99.85%\n",
      "Val Loss: 0.2091, Val Acc: 93.08%, Val Top-5 Acc: 100.00%\n",
      "Epoch 130/200 - Train Loss: 0.0058, Train Acc: 99.85%\n",
      "Val Loss: 0.1425, Val Acc: 96.38%, Val Top-5 Acc: 100.00%\n",
      "Epoch 131/200 - Train Loss: 0.0017, Train Acc: 99.94%\n",
      "Val Loss: 0.1801, Val Acc: 94.22%, Val Top-5 Acc: 100.00%\n",
      "Epoch 132/200 - Train Loss: 0.0006, Train Acc: 99.99%\n",
      "Val Loss: 0.1484, Val Acc: 95.90%, Val Top-5 Acc: 100.00%\n",
      "Epoch 133/200 - Train Loss: 0.0005, Train Acc: 99.99%\n",
      "Val Loss: 0.1512, Val Acc: 95.50%, Val Top-5 Acc: 100.00%\n",
      "Epoch 134/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.1381, Val Acc: 95.84%, Val Top-5 Acc: 100.00%\n",
      "Epoch 135/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.1576, Val Acc: 95.42%, Val Top-5 Acc: 100.00%\n",
      "Epoch 136/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.1347, Val Acc: 95.92%, Val Top-5 Acc: 100.00%\n",
      "Epoch 137/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.1318, Val Acc: 95.98%, Val Top-5 Acc: 100.00%\n",
      "Epoch 138/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.1297, Val Acc: 95.96%, Val Top-5 Acc: 100.00%\n",
      "Epoch 139/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.1519, Val Acc: 95.20%, Val Top-5 Acc: 100.00%\n",
      "Epoch 140/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.1220, Val Acc: 96.16%, Val Top-5 Acc: 100.00%\n",
      "Epoch 141/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.1071, Val Acc: 96.56%, Val Top-5 Acc: 100.00%\n",
      "Epoch 142/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.1201, Val Acc: 96.20%, Val Top-5 Acc: 100.00%\n",
      "Epoch 143/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.1084, Val Acc: 96.50%, Val Top-5 Acc: 100.00%\n",
      "Epoch 144/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.1644, Val Acc: 95.10%, Val Top-5 Acc: 100.00%\n",
      "Epoch 145/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.1379, Val Acc: 95.88%, Val Top-5 Acc: 100.00%\n",
      "Epoch 146/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.1383, Val Acc: 95.68%, Val Top-5 Acc: 100.00%\n",
      "Epoch 147/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.0933, Val Acc: 97.26%, Val Top-5 Acc: 100.00%\n",
      "Epoch 148/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.1118, Val Acc: 96.52%, Val Top-5 Acc: 100.00%\n",
      "Epoch 149/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.1237, Val Acc: 96.18%, Val Top-5 Acc: 100.00%\n",
      "Epoch 150/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.1177, Val Acc: 96.24%, Val Top-5 Acc: 100.00%\n",
      "Epoch 151/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.0900, Val Acc: 97.32%, Val Top-5 Acc: 100.00%\n",
      "Epoch 152/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.1138, Val Acc: 96.32%, Val Top-5 Acc: 100.00%\n",
      "Epoch 153/200 - Train Loss: 0.0056, Train Acc: 99.89%\n",
      "Val Loss: 4.1661, Val Acc: 43.56%, Val Top-5 Acc: 98.40%\n",
      "Epoch 154/200 - Train Loss: 0.0131, Train Acc: 99.64%\n",
      "Val Loss: 0.1321, Val Acc: 95.70%, Val Top-5 Acc: 100.00%\n",
      "Epoch 155/200 - Train Loss: 0.0008, Train Acc: 99.99%\n",
      "Val Loss: 0.1107, Val Acc: 96.38%, Val Top-5 Acc: 100.00%\n",
      "Epoch 156/200 - Train Loss: 0.0003, Train Acc: 100.00%\n",
      "Val Loss: 0.0921, Val Acc: 97.10%, Val Top-5 Acc: 100.00%\n",
      "Epoch 157/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.0925, Val Acc: 96.96%, Val Top-5 Acc: 100.00%\n",
      "Epoch 158/200 - Train Loss: 0.0012, Train Acc: 99.97%\n",
      "Val Loss: 0.1845, Val Acc: 94.48%, Val Top-5 Acc: 100.00%\n",
      "Epoch 159/200 - Train Loss: 0.0022, Train Acc: 99.93%\n",
      "Val Loss: 0.2872, Val Acc: 91.54%, Val Top-5 Acc: 100.00%\n",
      "Epoch 160/200 - Train Loss: 0.0004, Train Acc: 99.99%\n",
      "Val Loss: 0.1586, Val Acc: 94.58%, Val Top-5 Acc: 100.00%\n",
      "Epoch 161/200 - Train Loss: 0.0032, Train Acc: 99.89%\n",
      "Val Loss: 0.2790, Val Acc: 90.96%, Val Top-5 Acc: 100.00%\n",
      "Epoch 162/200 - Train Loss: 0.0008, Train Acc: 99.98%\n",
      "Val Loss: 0.1559, Val Acc: 94.66%, Val Top-5 Acc: 100.00%\n",
      "Epoch 163/200 - Train Loss: 0.0008, Train Acc: 99.97%\n",
      "Val Loss: 0.2203, Val Acc: 93.42%, Val Top-5 Acc: 100.00%\n",
      "Epoch 164/200 - Train Loss: 0.0021, Train Acc: 99.93%\n",
      "Val Loss: 0.1793, Val Acc: 93.66%, Val Top-5 Acc: 100.00%\n",
      "Epoch 165/200 - Train Loss: 0.0031, Train Acc: 99.91%\n",
      "Val Loss: 0.3242, Val Acc: 91.86%, Val Top-5 Acc: 99.90%\n",
      "Epoch 166/200 - Train Loss: 0.0002, Train Acc: 100.00%\n",
      "Val Loss: 0.2489, Val Acc: 93.56%, Val Top-5 Acc: 99.94%\n",
      "Epoch 167/200 - Train Loss: 0.0010, Train Acc: 99.99%\n",
      "Val Loss: 0.1728, Val Acc: 95.00%, Val Top-5 Acc: 100.00%\n",
      "Epoch 168/200 - Train Loss: 0.0010, Train Acc: 99.98%\n",
      "Val Loss: 0.2001, Val Acc: 93.86%, Val Top-5 Acc: 100.00%\n",
      "Epoch 169/200 - Train Loss: 0.0027, Train Acc: 99.95%\n",
      "Val Loss: 0.1661, Val Acc: 94.62%, Val Top-5 Acc: 100.00%\n",
      "Epoch 170/200 - Train Loss: 0.0013, Train Acc: 99.97%\n",
      "Val Loss: 0.2604, Val Acc: 92.22%, Val Top-5 Acc: 100.00%\n",
      "Epoch 171/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.2627, Val Acc: 92.84%, Val Top-5 Acc: 100.00%\n",
      "Epoch 172/200 - Train Loss: 0.0024, Train Acc: 99.93%\n",
      "Val Loss: 0.2920, Val Acc: 91.08%, Val Top-5 Acc: 99.98%\n",
      "Epoch 173/200 - Train Loss: 0.0022, Train Acc: 99.94%\n",
      "Val Loss: 0.2312, Val Acc: 93.00%, Val Top-5 Acc: 100.00%\n",
      "Epoch 174/200 - Train Loss: 0.0016, Train Acc: 99.96%\n",
      "Val Loss: 0.1187, Val Acc: 96.12%, Val Top-5 Acc: 100.00%\n",
      "Epoch 175/200 - Train Loss: 0.0014, Train Acc: 99.97%\n",
      "Val Loss: 0.1655, Val Acc: 94.50%, Val Top-5 Acc: 100.00%\n",
      "Epoch 176/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.1801, Val Acc: 94.06%, Val Top-5 Acc: 100.00%\n",
      "Epoch 177/200 - Train Loss: 0.0007, Train Acc: 99.98%\n",
      "Val Loss: 0.2455, Val Acc: 92.64%, Val Top-5 Acc: 100.00%\n",
      "Epoch 178/200 - Train Loss: 0.0016, Train Acc: 99.95%\n",
      "Val Loss: 0.2041, Val Acc: 94.30%, Val Top-5 Acc: 100.00%\n",
      "Epoch 179/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.1817, Val Acc: 95.02%, Val Top-5 Acc: 100.00%\n",
      "Epoch 180/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.1894, Val Acc: 94.56%, Val Top-5 Acc: 100.00%\n",
      "Epoch 181/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.3554, Val Acc: 90.08%, Val Top-5 Acc: 100.00%\n",
      "Epoch 182/200 - Train Loss: 0.0014, Train Acc: 99.95%\n",
      "Val Loss: 0.2065, Val Acc: 93.86%, Val Top-5 Acc: 100.00%\n",
      "Epoch 183/200 - Train Loss: 0.0054, Train Acc: 99.87%\n",
      "Val Loss: 0.1265, Val Acc: 96.00%, Val Top-5 Acc: 99.76%\n",
      "Epoch 184/200 - Train Loss: 0.0017, Train Acc: 99.96%\n",
      "Val Loss: 0.0856, Val Acc: 97.00%, Val Top-5 Acc: 100.00%\n",
      "Epoch 185/200 - Train Loss: 0.0005, Train Acc: 99.99%\n",
      "Val Loss: 0.1107, Val Acc: 95.98%, Val Top-5 Acc: 100.00%\n",
      "Epoch 186/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.1074, Val Acc: 96.22%, Val Top-5 Acc: 100.00%\n",
      "Epoch 187/200 - Train Loss: 0.0016, Train Acc: 99.94%\n",
      "Val Loss: 0.1359, Val Acc: 96.50%, Val Top-5 Acc: 100.00%\n",
      "Epoch 188/200 - Train Loss: 0.0005, Train Acc: 99.99%\n",
      "Val Loss: 0.0942, Val Acc: 97.06%, Val Top-5 Acc: 100.00%\n",
      "Epoch 189/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.0805, Val Acc: 97.38%, Val Top-5 Acc: 100.00%\n",
      "Epoch 190/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.0866, Val Acc: 97.32%, Val Top-5 Acc: 100.00%\n",
      "Epoch 191/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.0809, Val Acc: 97.76%, Val Top-5 Acc: 100.00%\n",
      "Epoch 192/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.0811, Val Acc: 97.36%, Val Top-5 Acc: 100.00%\n",
      "Epoch 193/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.0766, Val Acc: 97.62%, Val Top-5 Acc: 100.00%\n",
      "Epoch 194/200 - Train Loss: 0.0024, Train Acc: 99.94%\n",
      "Val Loss: 0.1703, Val Acc: 95.14%, Val Top-5 Acc: 100.00%\n",
      "Epoch 195/200 - Train Loss: 0.0069, Train Acc: 99.83%\n",
      "Val Loss: 0.2142, Val Acc: 92.74%, Val Top-5 Acc: 100.00%\n",
      "Epoch 196/200 - Train Loss: 0.0006, Train Acc: 99.99%\n",
      "Val Loss: 0.1299, Val Acc: 96.08%, Val Top-5 Acc: 100.00%\n",
      "Epoch 197/200 - Train Loss: 0.0002, Train Acc: 99.99%\n",
      "Val Loss: 0.0789, Val Acc: 97.42%, Val Top-5 Acc: 100.00%\n",
      "Epoch 198/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.1061, Val Acc: 96.66%, Val Top-5 Acc: 100.00%\n",
      "Epoch 199/200 - Train Loss: 0.0001, Train Acc: 100.00%\n",
      "Val Loss: 0.0748, Val Acc: 97.74%, Val Top-5 Acc: 100.00%\n",
      "Epoch 200/200 - Train Loss: 0.0000, Train Acc: 100.00%\n",
      "Val Loss: 0.0959, Val Acc: 97.06%, Val Top-5 Acc: 100.00%\n",
      "Test accuracy: 94.86%\n",
      "Test top-5 accuracy: 100.00%\n",
      "\n",
      "Báo cáo phân loại:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Step_1       0.76      0.94      0.84       300\n",
      "      Step_2       0.98      0.95      0.96       700\n",
      "      Step_3       0.89      0.92      0.91       600\n",
      "      Step_4       1.00      0.95      0.98      1400\n",
      "      Step_5       0.91      0.99      0.95       900\n",
      "      Step_6       1.00      0.93      0.96      1100\n",
      "\n",
      "    accuracy                           0.95      5000\n",
      "   macro avg       0.92      0.95      0.93      5000\n",
      "weighted avg       0.95      0.95      0.95      5000\n",
      "\n",
      "\n",
      "Ma trận nhầm lẫn:\n",
      "[[ 281   15    4    0    0    0]\n",
      " [  17  666    9    0    7    1]\n",
      " [  45    0  553    0    2    0]\n",
      " [   7    0    0 1333   60    0]\n",
      " [  12    0    1    0  887    0]\n",
      " [   6    0   51    0   20 1023]]\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo model mới và các thành phần khác\n",
    "model = HandWashResNet().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Huấn luyện\n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train_one_epoch(model, trainloader, criterion, optimizer, DEVICE)\n",
    "    val_loss, val_acc, val_top5_acc, _, _ = evaluate(model, validloader, criterion, DEVICE)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, Val Top-5 Acc: {val_top5_acc:.2f}%\")\n",
    "    if val_loss < best_val_loss and val_acc > best_val_acc:\n",
    "        best_val_loss = val_loss\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model, 'best_sequential_model.pt')\n",
    "        print(f\"Saved best full model at epoch {epoch+1} with val_loss: {val_loss:.4f}, val_acc: {val_acc:.2f}%\")\n",
    "\n",
    "# Đánh giá mô hình\n",
    "test_loss, test_acc, test_top5_acc, test_preds, test_labels = evaluate(model, testloader, criterion, DEVICE)\n",
    "print(f\"Test accuracy: {test_acc:.2f}%\")\n",
    "print(f\"Test top-5 accuracy: {test_top5_acc:.2f}%\")\n",
    "print(\"\\nBáo cáo phân loại:\")\n",
    "print(classification_report(test_labels, test_preds, target_names=CLASSES))\n",
    "print(\"\\nMa trận nhầm lẫn:\")\n",
    "print(confusion_matrix(test_labels, test_preds))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7964111,
     "sourceId": 12608119,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7519.444771,
   "end_time": "2025-07-30T02:56:05.355536",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-30T00:50:45.910765",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
